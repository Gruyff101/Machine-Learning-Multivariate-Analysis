{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Pre-processing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load & Pre-process\n",
    "df = pd.read_csv(\"JGM.csv\")\n",
    "df = df.drop(columns=[\"team_nr\", \"tijd\"])\n",
    "df[\"gehaald\"] = df[\"gehaald\"].map({1: 0, 2: 1})\n",
    "\n",
    "X = df.drop(\"gehaald\", axis=1)\n",
    "y = df[\"gehaald\"]\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "pipe_base = Pipeline([(\"model\", model)])\n",
    "pipe_base.fit(X_train, y_train)\n",
    "y_pred = pipe_base.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores:\n",
      "Accuracy: 0.7457627118644068\n",
      "precision_score: 0.7291666666666666\n",
      "recall_score: 0.9459459459459459\n",
      "f1_score: 0.8235294117647058\n",
      "---\n",
      "[[ 9 13]\n",
      " [ 2 35]]\n",
      "---\n",
      "Cross-val scores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73972603 0.85333333 0.77333333 0.75       0.76056338]\n",
      "0.7753912148691234 - 0.04053589218356915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "\n",
    "print(\"Test scores:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"precision_score:\", precision_score(y_test, y_pred))\n",
    "print(\"recall_score:\", recall_score(y_test, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred))\n",
    "print(\"---\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"---\")\n",
    "print(\"Cross-val scores:\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipe_base, X, y, cv=cv, scoring=\"f1\")\n",
    "\n",
    "print(cv_scores)\n",
    "print(f\"{cv_scores.mean()} - {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) MinMax-Scaler model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minMaxScaler = MinMaxScaler()\n",
    "\n",
    "# Train\n",
    "pipe_minmax = Pipeline([(\"scaler\", minMaxScaler), (\"model\", model)])\n",
    "pipe_minmax.fit(X_train, y_train)\n",
    "y_pred = pipe_minmax.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores:\n",
      "Accuracy: 0.711864406779661\n",
      "precision_score: 0.7083333333333334\n",
      "recall_score: 0.918918918918919\n",
      "f1_score: 0.8\n",
      "---\n",
      "[[ 8 14]\n",
      " [ 3 34]]\n",
      "---\n",
      "Cross-val scores:\n",
      "[0.82051282 0.82051282 0.84210526 0.78378378 0.8       ]\n",
      "0.8133829375934638 - 0.019909070152050144\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "\n",
    "print(\"Test scores:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"precision_score:\", precision_score(y_test, y_pred))\n",
    "print(\"recall_score:\", recall_score(y_test, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred))\n",
    "print(\"---\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"---\")\n",
    "print(\"Cross-val scores:\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipe_minmax, X, y, cv=cv, scoring=\"f1\")\n",
    "\n",
    "print(cv_scores)\n",
    "print(f\"{cv_scores.mean()} - {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Standardized-Scaler model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "\n",
    "# Train\n",
    "pipe_standard = Pipeline([(\"scaler\", stdScaler), (\"model\", model)])\n",
    "pipe_standard.fit(X_train, y_train)\n",
    "y_pred = pipe_standard.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores:\n",
      "Accuracy: 0.7457627118644068\n",
      "precision_score: 0.72\n",
      "recall_score: 0.972972972972973\n",
      "f1_score: 0.8275862068965517\n",
      "---\n",
      "[[ 8 14]\n",
      " [ 1 36]]\n",
      "---\n",
      "Cross-val scores:\n",
      "[0.72222222 0.87179487 0.67567568 0.75675676 0.76712329]\n",
      "0.758714562824152 - 0.0649443510038087\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "\n",
    "print(\"Test scores:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"precision_score:\", precision_score(y_test, y_pred))\n",
    "print(\"recall_score:\", recall_score(y_test, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test, y_pred))\n",
    "print(\"---\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"---\")\n",
    "print(\"Cross-val scores:\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipe_standard, X, y, cv=cv, scoring=\"f1\")\n",
    "\n",
    "print(cv_scores)\n",
    "print(f\"{cv_scores.mean()} - {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Standardized model - Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Preprocessing\n",
    "X_feature = SelectKBest(chi2).fit_transform(X, y)\n",
    "X_train_feature, X_test_feature, y_train_feature, y_test_feature = train_test_split(X_feature, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train\n",
    "pipe_feature = Pipeline([(\"scaler\", stdScaler), (\"model\", model)])\n",
    "pipe_feature.fit(X_train_feature, y_train_feature)\n",
    "y_pred = pipe_feature.predict(X_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores:\n",
      "Accuracy: 0.847457627118644\n",
      "precision_score: 0.8333333333333334\n",
      "recall_score: 0.9459459459459459\n",
      "f1_score: 0.8860759493670886\n",
      "---\n",
      "[[15  7]\n",
      " [ 2 35]]\n",
      "---\n",
      "Cross-val scores:\n",
      "[0.775      0.83783784 0.88       0.77333333 0.82857143]\n",
      "0.8189485199485199 - 0.04046951339655217\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "\n",
    "print(\"Test scores:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_feature, y_pred))\n",
    "print(\"precision_score:\", precision_score(y_test_feature, y_pred))\n",
    "print(\"recall_score:\", recall_score(y_test_feature, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test_feature, y_pred))\n",
    "print(\"---\")\n",
    "print(confusion_matrix(y_test_feature, y_pred))\n",
    "print(\"---\")\n",
    "print(\"Cross-val scores:\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipe_feature, X_feature, y, cv=cv, scoring=\"f1\")\n",
    "\n",
    "print(cv_scores)\n",
    "print(f\"{cv_scores.mean()} - {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Standardized, feature-selected, model - Hyperparameter optimalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 342 candidates, totalling 1710 fits\n",
      "{'model__C': np.float64(0.2), 'model__max_iter': 25, 'model__penalty': 'l2'}\n",
      "0.8158960461254441\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Grid Search\n",
    "param_grid = {\n",
    "    \"model__penalty\": [\"l2\", None],\n",
    "    \"model__C\": np.arange(0.1, 2, 0.1),\n",
    "    \"model__max_iter\": range(25, 250, 25)\n",
    "}\n",
    "\n",
    "gridsearch = GridSearchCV(pipe_feature, param_grid, n_jobs=-1, scoring=\"f1\", verbose=5)\n",
    "gridsearch.fit(X_train_feature, y_train_feature)\n",
    "\n",
    "print(gridsearch.best_params_)\n",
    "print(gridsearch.best_score_)\n",
    "\n",
    "best_model = gridsearch.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores:\n",
      "Accuracy: 0.847457627118644\n",
      "precision_score: 0.8333333333333334\n",
      "recall_score: 0.9459459459459459\n",
      "f1_score: 0.8860759493670886\n",
      "---\n",
      "[[15  7]\n",
      " [ 2 35]]\n",
      "---\n",
      "Cross-val scores:\n",
      "[0.775      0.83783784 0.88       0.78947368 0.81690141]\n",
      "0.8198425860998138 - 0.0371066619040764\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "\n",
    "print(\"Test scores:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_feature, y_pred))\n",
    "print(\"precision_score:\", precision_score(y_test_feature, y_pred))\n",
    "print(\"recall_score:\", recall_score(y_test_feature, y_pred))\n",
    "print(\"f1_score:\", f1_score(y_test_feature, y_pred))\n",
    "print(\"---\")\n",
    "print(confusion_matrix(y_test_feature, y_pred))\n",
    "print(\"---\")\n",
    "print(\"Cross-val scores:\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_model, X_feature, y, cv=cv, scoring=\"f1\")\n",
    "\n",
    "print(cv_scores)\n",
    "print(f\"{cv_scores.mean()} - {cv_scores.std()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
