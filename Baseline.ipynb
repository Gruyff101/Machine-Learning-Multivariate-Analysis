{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Freark\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default results:\n",
      "                    Classifier  Test - Accuracy  Test - F1  \\\n",
      "10               MLPClassifier         0.728814   0.794872   \n",
      "7                   GaussianNB         0.661017   0.729730   \n",
      "4       RandomForestClassifier         0.677966   0.765432   \n",
      "2                          SVC         0.610169   0.757895   \n",
      "0           LogisticRegression         0.661017   0.743590   \n",
      "5   GradientBoostingClassifier         0.779661   0.839506   \n",
      "6           AdaBoostClassifier         0.644068   0.734177   \n",
      "3       DecisionTreeClassifier         0.661017   0.729730   \n",
      "8              RidgeClassifier         0.745763   0.805195   \n",
      "9   LinearDiscriminantAnalysis         0.745763   0.805195   \n",
      "1         KNeighborsClassifier         0.644068   0.727273   \n",
      "\n",
      "    Cross-validation F1  \n",
      "10             0.791706  \n",
      "7              0.771710  \n",
      "4              0.771637  \n",
      "2              0.768967  \n",
      "0              0.747543  \n",
      "5              0.740835  \n",
      "6              0.725363  \n",
      "3              0.721240  \n",
      "8              0.709005  \n",
      "9              0.709005  \n",
      "1              0.706656  \n",
      "\n",
      "Scaled results:\n",
      "                    Classifier  Test - Accuracy  Test - F1  \\\n",
      "2                          SVC         0.728814   0.809524   \n",
      "10               MLPClassifier         0.711864   0.784810   \n",
      "5   GradientBoostingClassifier         0.762712   0.829268   \n",
      "1         KNeighborsClassifier         0.745763   0.805195   \n",
      "4       RandomForestClassifier         0.762712   0.825000   \n",
      "7                   GaussianNB         0.661017   0.729730   \n",
      "0           LogisticRegression         0.677966   0.753247   \n",
      "6           AdaBoostClassifier         0.644068   0.734177   \n",
      "3       DecisionTreeClassifier         0.661017   0.743590   \n",
      "8              RidgeClassifier         0.745763   0.805195   \n",
      "9   LinearDiscriminantAnalysis         0.745763   0.805195   \n",
      "\n",
      "    Cross-validation F1  \n",
      "2              0.788087  \n",
      "10             0.780341  \n",
      "5              0.779267  \n",
      "1              0.778478  \n",
      "4              0.777510  \n",
      "7              0.771710  \n",
      "0              0.752918  \n",
      "6              0.739649  \n",
      "3              0.734391  \n",
      "8              0.709005  \n",
      "9              0.709005  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "df = pd.read_csv(\"JGM.csv\")\n",
    "df = df.drop(columns=[\"team_nr\", \"tijd\"])\n",
    "df[\"gehaald\"] = df['gehaald'].map({1: 0, 2: 1})\n",
    "\n",
    "X = df.drop(\"gehaald\", axis=1)\n",
    "y = df[\"gehaald\"]\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# List of classifiers to test\n",
    "classifiers = [\n",
    "    LogisticRegression(max_iter=200),\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    RidgeClassifier(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    MLPClassifier(max_iter=500)\n",
    "]\n",
    "\n",
    "# Function to evaluate classifiers\n",
    "def evaluate_classifiers(classifiers, X_train, X_test, y_train, y_test):\n",
    "    results = []\n",
    "\n",
    "    for clf in classifiers:\n",
    "\n",
    "        clf_name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Accuracy on test data\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation score\n",
    "        cv_score = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"f1\").mean()\n",
    "        \n",
    "        results.append({\n",
    "            'Classifier': clf_name,\n",
    "            'Test - Accuracy': accuracy,\n",
    "            \"Test - F1\": f1,\n",
    "            'Cross-validation F1': cv_score\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame to display results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "# Run the evaluation\n",
    "results_df = evaluate_classifiers(classifiers, X_train, X_test, y_train, y_test)\n",
    "results_df_scaled = evaluate_classifiers(classifiers, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nDefault results:\")\n",
    "print(results_df.sort_values(by='Cross-validation F1', ascending=False))\n",
    "\n",
    "print(\"\\nScaled results:\")\n",
    "print(results_df_scaled.sort_values(by='Cross-validation F1', ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
